{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpq6g7racZ65"
      },
      "source": [
        "\n",
        "# Инструменты для работы с языком"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x57fns1XcZ7E"
      },
      "source": [
        "... или зачем нужна предобработка.\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/10_Aehfbxgr3fxXPgI1gM5BTU8yOy-Z4U)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_WSekS7cZ7T"
      },
      "source": [
        "## Задача: классификация твитов по тональности\n",
        "\n",
        "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
        "\n",
        "Классификацию по тональности используют в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
        "\n",
        "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo6Z2ORzcZ7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f59d3e-3139-4463-bf25-26a044f7e897"
      },
      "source": [
        "# если у вас линукс / мак / colab или ещё какая-то среда, в которой работает wget, можно так:\n",
        "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
        "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-02 15:24:12--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/6mg7rw3wltux83q2o4ah4/positive.csv?rlkey=cvruhzofza9kkfxwzyp2vskfd [following]\n",
            "--2025-09-02 15:24:12--  https://www.dropbox.com/scl/fi/6mg7rw3wltux83q2o4ah4/positive.csv?rlkey=cvruhzofza9kkfxwzyp2vskfd\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf65e8c9ccc21a698ede7e56e7c.dl.dropboxusercontent.com/cd/0/inline/CwmGsB5GMzmLXbDRKrkuW4ft3_Q1qXlh-mi4I0zLXJG0LoHzzZ2ONpnY-HgJD8XBNDWxgwsfFIWYejB2P9w0ySt2pzdHoDPVJlxeXNDFXM-L8Xpshy06jHvRbvTkug69FMQ/file# [following]\n",
            "--2025-09-02 15:24:12--  https://ucf65e8c9ccc21a698ede7e56e7c.dl.dropboxusercontent.com/cd/0/inline/CwmGsB5GMzmLXbDRKrkuW4ft3_Q1qXlh-mi4I0zLXJG0LoHzzZ2ONpnY-HgJD8XBNDWxgwsfFIWYejB2P9w0ySt2pzdHoDPVJlxeXNDFXM-L8Xpshy06jHvRbvTkug69FMQ/file\n",
            "Resolving ucf65e8c9ccc21a698ede7e56e7c.dl.dropboxusercontent.com (ucf65e8c9ccc21a698ede7e56e7c.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to ucf65e8c9ccc21a698ede7e56e7c.dl.dropboxusercontent.com (ucf65e8c9ccc21a698ede7e56e7c.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26233379 (25M) [text/plain]\n",
            "Saving to: ‘positive.csv’\n",
            "\n",
            "positive.csv        100%[===================>]  25.02M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-09-02 15:24:13 (243 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
            "\n",
            "--2025-09-02 15:24:13--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/wui0xz78kpna56690uej4/negative.csv?rlkey=309xeou9u3rtbejw9stb13wfr [following]\n",
            "--2025-09-02 15:24:13--  https://www.dropbox.com/scl/fi/wui0xz78kpna56690uej4/negative.csv?rlkey=309xeou9u3rtbejw9stb13wfr\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc4e0864b24b5e40da928476f6f6.dl.dropboxusercontent.com/cd/0/inline/Cwlhmpk7NYtOaPKILVSuddiTNqUpPmebGvwPVfoUbg8B3tbq47-I-g7HK19oOdQ6DbKufiqevEvvR-EXk4Mz0iPbJPiVAbaVzozoT-VF8nmgfu2VJDLDLNiV1cKvSgcsrBg/file# [following]\n",
            "--2025-09-02 15:24:13--  https://uc4e0864b24b5e40da928476f6f6.dl.dropboxusercontent.com/cd/0/inline/Cwlhmpk7NYtOaPKILVSuddiTNqUpPmebGvwPVfoUbg8B3tbq47-I-g7HK19oOdQ6DbKufiqevEvvR-EXk4Mz0iPbJPiVAbaVzozoT-VF8nmgfu2VJDLDLNiV1cKvSgcsrBg/file\n",
            "Resolving uc4e0864b24b5e40da928476f6f6.dl.dropboxusercontent.com (uc4e0864b24b5e40da928476f6f6.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to uc4e0864b24b5e40da928476f6f6.dl.dropboxusercontent.com (uc4e0864b24b5e40da928476f6f6.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24450101 (23M) [text/plain]\n",
            "Saving to: ‘negative.csv’\n",
            "\n",
            "negative.csv        100%[===================>]  23.32M   147MB/s    in 0.2s    \n",
            "\n",
            "2025-09-02 15:24:14 (147 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw5R6bvGcZ8i"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-YuDuo8cZ9K"
      },
      "source": [
        "# считываем данные и заполняем общий датасет\n",
        "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
        "positive['label'] = ['positive'] * len(positive)\n",
        "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
        "negative['label'] = ['negative'] * len(negative)\n",
        "df = pd.concat([positive,negative])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0kATS9XcZ-N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "216539e0-7f58-4a47-d85f-28581cb3f89c"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     label\n",
              "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
              "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
              "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
              "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
              "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-524c051b-0d02-445c-8dd9-32c1fcae56af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>111918</th>\n",
              "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111919</th>\n",
              "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111920</th>\n",
              "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111921</th>\n",
              "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111922</th>\n",
              "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-524c051b-0d02-445c-8dd9-32c1fcae56af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-524c051b-0d02-445c-8dd9-32c1fcae56af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-524c051b-0d02-445c-8dd9-32c1fcae56af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-42b30cde-00f0-444f-a7f2-2b9009199292\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42b30cde-00f0-444f-a7f2-2b9009199292')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-42b30cde-00f0-444f-a7f2-2b9009199292 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0441\\u043a\\u0443\\u0447\\u0430\\u044e \\u0442\\u0430\\u043a :-( \\u0442\\u043e\\u043b\\u044c\\u043a\\u043e @taaannyaaa \\u0432\\u043f\\u0440\\u0430\\u0432\\u043b\\u044f\\u0435\\u0442 \\u043c\\u043e\\u0437\\u0433\\u0438, \\u043d\\u043e \\u044f \\u0432\\u0441\\u0435 \\u0440\\u0430\\u0432\\u043d\\u043e \\u0441\\u043a\\u0443\\u0447\\u0430\\u044e\",\n          \"\\u0422\\u0430\\u043a\\u0441\\u0438 \\u0432\\u0435\\u0437\\u0435\\u0442 \\u043c\\u0435\\u043d\\u044f \\u043d\\u0430 \\u0440\\u0430\\u0431\\u043e\\u0442\\u0443. \\u0420\\u0430\\u0437\\u0434\\u0443\\u043c\\u044b\\u0432\\u0430\\u044e \\u043f\\u0440\\u0438\\u043f\\u043b\\u0430\\u0442\\u0438\\u0442\\u044c, \\u0447\\u0442\\u043e\\u0431\\u044b \\u043c\\u0435\\u043d\\u044f \\u0432\\u0442\\u0430\\u0449\\u0438\\u043b\\u0438 \\u043d\\u0430 \\u043f\\u044f\\u0442\\u044b\\u0439 \\u044d\\u0442\\u0430\\u0436. \\u041b\\u0438\\u0444\\u0442\\u0430 \\u0442\\u043e \\u043d\\u0435\\u0442 :(\",\n          \"\\u0412\\u043e\\u0442 \\u0438 \\u0432 \\u0448\\u043a\\u043e\\u043b\\u0443, \\u0432 \\u0433\\u043e\\u0432\\u043d\\u043e \\u044d\\u0442\\u043e \\u0438\\u0434\\u0442\\u0438 \\u0443\\u0436\\u0435 \\u043d\\u0430\\u0434\\u043e(\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytgI330KcZ-w"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osqaPQk0cZ_T"
      },
      "source": [
        "## Baseline: классификация необработанных n-грамм\n",
        "\n",
        "### Векторизаторы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reJdvwmXcZ_a"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jTvJ3pNcZ_y"
      },
      "source": [
        "Что такое n-граммы:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU7nGQhicZ_5"
      },
      "source": [
        "from nltk import ngrams"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoNSXICycaAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f22fd3-680e-45e5-f12a-5a28ef81741f"
      },
      "source": [
        "sent = 'Если б мне платили каждый раз'.split()\n",
        "list(ngrams(sent, 1)) # униграммы"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GyuVzrRcaBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a1c056-a913-4be6-a621-2185ad3cfd71"
      },
      "source": [
        "list(ngrams(sent, 2)) # биграммы"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б'),\n",
              " ('б', 'мне'),\n",
              " ('мне', 'платили'),\n",
              " ('платили', 'каждый'),\n",
              " ('каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS5WihstcaB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74cd0f79-5c69-4fa3-8a79-b4fbdb950ef4"
      },
      "source": [
        "list(ngrams(sent, 3)) # триграммы"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне'),\n",
              " ('б', 'мне', 'платили'),\n",
              " ('мне', 'платили', 'каждый'),\n",
              " ('платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5yDWI_IcaCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f70e6b-80a2-45fb-d915-726bc0c502d0"
      },
      "source": [
        "list(ngrams(sent, 5)) # ... пентаграммы?"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
              " ('б', 'мне', 'платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on8d-6XRcaDX"
      },
      "source": [
        "Самый простой способ извлечь признаки из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
        "\n",
        "Объект `CountVectorizer` делает простую вещь:\n",
        "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грамм во всём корпусе\n",
        "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRYceaT0caDf"
      },
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgqrGV_ycaEP"
      },
      "source": [
        "ngram_range отвечает за то, какие n-граммы мы используем в качестве признаков:<br/>\n",
        "ngram_range=(1, 1) -- униграммы<br/>\n",
        "ngram_range=(3, 3) -- триграммы<br/>\n",
        "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
        "\n",
        "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ih5TZbCcaET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b75e7be-9629-4990-8186-d341175453eb"
      },
      "source": [
        "list(vec.vocabulary_.items())[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('katyamissyou', 45506),\n",
              " ('хойова', 233900),\n",
              " ('как', 142553),\n",
              " ('то', 222111),\n",
              " ('што', 239750),\n",
              " ('делаешь', 124301),\n",
              " ('daytona_love', 24194),\n",
              " ('оксана', 173144),\n",
              " ('разблокируй', 199727),\n",
              " ('меня', 157566)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tdvqOJbcaE3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "189840c8-c1d0-4c9a-d859-c4372d227f81"
      },
      "source": [
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_O51yvlcaFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea46b9d-ed79-4a53-ecdc-5c5b9359e6d4"
      },
      "source": [
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.76      0.76     27895\n",
            "    positive       0.77      0.76      0.77     28814\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7Z6ng4UcaF6"
      },
      "source": [
        "Попробуем сделать то же самое для триграмм:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwBN7AXUcaGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d26778b-9a37-4671-ffb8-24af051a2278"
      },
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 3))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.78      0.78     27959\n",
            "    positive       0.79      0.78      0.78     28750\n",
            "\n",
            "    accuracy                           0.78     56709\n",
            "   macro avg       0.78      0.78      0.78     56709\n",
            "weighted avg       0.78      0.78      0.78     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO2Llu21caGZ"
      },
      "source": [
        "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeEsDhIBcaGd"
      },
      "source": [
        "## TF-IDF векторизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcagy0XNcaGf"
      },
      "source": [
        "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
        "\n",
        "Как считается tf-idf:\n",
        "\n",
        "TF (term frequency) – относительная частотность слова в документе:\n",
        "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
        "\n",
        "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
        "\n",
        "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
        "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
        "\n",
        "`t` -- слово (term), `D` -- коллекция документов\n",
        "\n",
        "Перемножаем их:\n",
        "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
        "\n",
        "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом\n",
        "количестве документов, у него высокий TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KaxOlBOcaGj"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLl5Zc_2caG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bee889f-4eab-425a-d5f8-e47b044ca6ab"
      },
      "source": [
        "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.77      0.75     26532\n",
            "    positive       0.79      0.75      0.77     30177\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JixM3zxIcaHN"
      },
      "source": [
        "В этот раз получилось хуже :( Вернёмся к `CountVectorizer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciJyLidscaHT"
      },
      "source": [
        "## Токенизация\n",
        "\n",
        "Токенизировать -- значит, поделить текст на слова, или *токены*.\n",
        "\n",
        "Самый наивный способ токенизировать текст -- разделить с помощью `split`. Но `split` упускает очень много всего, например, банально не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем. Поэтому лучше использовать готовые токенизаторы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZ0NrDYcaHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae025284-b5c3-4065-a53e-4e2eede0ff30"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zDIkXJhcaHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9e20a3-73ba-429c-f3ff-5c0abe7c8825"
      },
      "source": [
        "nltk.download('punkt_tab')\n",
        "example = 'Но не каждый хочет что-то исправлять:('\n",
        "word_tokenize(example)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8jrq1kXcaH4"
      },
      "source": [
        "В nltk вообще есть довольно много токенизаторов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvBhn0wicaH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be57166f-12d0-4621-d1c8-f5c273d28c78"
      },
      "source": [
        "from nltk import tokenize\n",
        "dir(tokenize)[:16]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BlanklineTokenizer',\n",
              " 'LegalitySyllableTokenizer',\n",
              " 'LineTokenizer',\n",
              " 'MWETokenizer',\n",
              " 'NLTKWordTokenizer',\n",
              " 'PunktSentenceTokenizer',\n",
              " 'PunktTokenizer',\n",
              " 'RegexpTokenizer',\n",
              " 'ReppTokenizer',\n",
              " 'SExprTokenizer',\n",
              " 'SpaceTokenizer',\n",
              " 'StanfordSegmenter',\n",
              " 'SyllableTokenizer',\n",
              " 'TabTokenizer',\n",
              " 'TextTilingTokenizer',\n",
              " 'ToktokTokenizer']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek23QFXWcaIR"
      },
      "source": [
        "Они умеют выдавать индексы начала и конца каждого токена:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xX94e04caIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812d07b4-8941-44c7-a5db-d53215c43bf9"
      },
      "source": [
        "wh_tok = tokenize.WhitespaceTokenizer()\n",
        "list(wh_tok.span_tokenize(example))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl9cdF2ycaIw"
      },
      "source": [
        "(если вам было интересно, зачем вообще включать в модуль токенизатор, который работает как `.split()` :))\n",
        "\n",
        "Некторые токенизаторы ведут себя специфично:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uSIiOBacaIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80091f1-17c4-4c66-f2d3-bcd68cc3e5f9"
      },
      "source": [
        "tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['do', \"n't\", 'stop', 'me']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ycih5W-caJO"
      },
      "source": [
        "Для некоторых задач это может быть полезно.\n",
        "\n",
        "А некоторые -- вообще не для текста на естественном языке (не очень понятно, зачем это в nltk :)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmgL5JRdcaJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6829c0-ed60-4dc4-d571-da6cb4ab0414"
      },
      "source": [
        "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(a (b c))', 'd', 'e', '(f)']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DkDk49-caJo"
      },
      "source": [
        "## Стоп-слова и пунктуация\n",
        "\n",
        "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMR9eNnQcaJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "392edf5b-c9c6-48ba-96b3-26952c97ef3c"
      },
      "source": [
        "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('russian'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGb_nU-mcaKO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "220e6e61-7cea-4c1c-ae9b-78cec937227e"
      },
      "source": [
        "from string import punctuation\n",
        "punctuation"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSHmwcW9caKl"
      },
      "source": [
        "noise = stopwords.words('russian') + list(punctuation)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-pn9DadcaK5"
      },
      "source": [
        "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-xuZ4HucaK8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "c00dd80e-d5f4-4d46-ed86-ab88734c66a0"
      },
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8839256f1174>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     return [\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return [\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/destructive.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Handles parentheses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/re.py\u001b[0m in \u001b[0;36m_subx\u001b[0;34m(pattern, template)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# literal replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBonc7nCcaLM"
      },
      "source": [
        "Получилось чуть лучше. Что ещё можно сделать?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VHLHQSkcaLQ"
      },
      "source": [
        "## Лемматизация\n",
        "\n",
        "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
        "* Во-первых, мы хотим рассматривать как отдельный признак каждое *слово*, а не каждую его отдельную форму.\n",
        "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
        "\n",
        "Для русского есть как минимум два хороших лемматизатора: mystem и pymorphy (но есть и другие, например, Natasha):\n",
        "\n",
        "### [Mystem](https://tech.yandex.ru/mystem/)\n",
        "Как с ним работать:\n",
        "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
        "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXfQU1Y-caLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a2ea71-40d5-4d0c-96fa-94eda47efe9a"
      },
      "source": [
        "!pip install pymystem3\n",
        "from pymystem3 import Mystem\n",
        "mystem_analyzer = Mystem()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymystem3\n",
            "  Downloading pymystem3-0.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pymystem3) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pymystem3) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pymystem3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pymystem3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pymystem3) (2025.8.3)\n",
            "Downloading pymystem3-0.2.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pymystem3\n",
            "Successfully installed pymystem3-0.2.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhXsc4D2caLi"
      },
      "source": [
        "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
        "* mystem_bin - путь к `mystem`, если их несколько\n",
        "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
        "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
        "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
        "\n",
        "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
        "\n",
        "Можно просто лемматизировать текст:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8i3HHbwcaLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfae071b-9fb6-4fa1-9b75-c53a09721184"
      },
      "source": [
        "print(mystem_analyzer.lemmatize(example))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ytQs6kcaL5"
      },
      "source": [
        "А можно получить грамматическую информацию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H1UsuoRcaL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d37e85f-8b9d-4ae4-ee00-3191aa9b3173"
      },
      "source": [
        "mystem_analyzer.analyze(example)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
              "  'text': 'Но'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'каждый',\n",
              "    'wt': 0.9985975799,\n",
              "    'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}],\n",
              "  'text': 'каждый'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'хотеть',\n",
              "    'wt': 1,\n",
              "    'gr': 'V,несов,пе=непрош,ед,изъяв,3-л'}],\n",
              "  'text': 'хочет'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'что-то', 'wt': 1, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}],\n",
              "  'text': 'что-то'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'исправлять', 'wt': 1, 'gr': 'V,пе=инф,несов'}],\n",
              "  'text': 'исправлять'},\n",
              " {'text': ':(\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrGypyhGcaMR"
      },
      "source": [
        "Давайте теперь попробуем лемматизатор майстема в качестве токенизатора."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSDYpuJhcaMV"
      },
      "source": [
        "import re\n",
        "def my_preproc(text):\n",
        "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
        "    text = mystem_analyzer.lemmatize(text)\n",
        "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flUY2rfocaMj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "911adfa5-506e-4988-958e-60cb9bd798c4"
      },
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8fbdae5300e4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_preproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-d959ae739e45>\u001b[0m in \u001b[0;36mmy_preproc\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[{}]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmystem_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'russian'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-d959ae739e45>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[{}]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmystem_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'russian'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[1;32m     19\u001b[0m         return [\n\u001b[1;32m     20\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36mraw\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m    230\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, fileid)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38iCzgMocaMw"
      },
      "source": [
        "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
        "Это модуль на питоне, довольно быстрый и с кучей функций."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Ba4QAKcaMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ebe44c4-b7cc-4342-87f6-d4fac52837a1"
      },
      "source": [
        "!pip install pymorphy3\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "pymorphy3_analyzer = MorphAnalyzer()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy3\n",
            "  Downloading pymorphy3-2.0.4-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting dawg2-python>=0.8.0 (from pymorphy3)\n",
            "  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.12/dist-packages (from pymorphy3) (75.2.0)\n",
            "Downloading pymorphy3-2.0.4-py3-none-any.whl (54 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3\n",
            "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.4 pymorphy3-dicts-ru-2.4.417150.4580142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBb0v0XCcaM_"
      },
      "source": [
        "pymorphy3 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrBhhlTocaNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d37479-0834-4de6-cd88-f941c49e9c42"
      },
      "source": [
        "ana = pymorphy3_analyzer.parse(sent[3])\n",
        "ana"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2471, 10),))]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih4ky-pzcaNR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52d9e8d0-d9ed-49cc-e71f-55d11423d635"
      },
      "source": [
        "ana[0].normal_form"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'платить'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L5Yt8TBeD0xF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R00b4vpucaNe"
      },
      "source": [
        "А теперь напишите аналогичную функцию для лемматизации с pymorphy3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4Z-P69ccaNg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prGblX94caNr"
      },
      "source": [
        "Что будет, если использовать её в качестве препроцессора?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EHMsrVJcaNu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwquMmyvcaN5"
      },
      "source": [
        "### mystem vs. pymorphy\n",
        "\n",
        "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
        "\n",
        "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZA_orFFcaN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d087e138-fbf4-48b3-fcfe-70362edc40d2"
      },
      "source": [
        "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
        "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
        "homonym3 = 'Мальчик разбил стекло в окне.'\n",
        "homonym4 = 'Мальчик разбил банку, и варенье медленно стекло со стола.'\n",
        "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
        "\n",
        "print(mystem_analyzer.analyze(homonym1)[-5])\n",
        "print(mystem_analyzer.analyze(homonym2)[0])\n",
        "\n",
        "print(mystem_analyzer.analyze(homonym3)[4])\n",
        "print(mystem_analyzer.analyze(homonym4)[-7])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292664, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
            "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n",
            "{'analysis': [{'lex': 'стекло', 'wt': 0.9853860572, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'стекло'}\n",
            "{'analysis': [{'lex': 'стекло', 'wt': 0.9853860572, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'стекло'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nATnTGScaOL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnF9jZVHcaOi"
      },
      "source": [
        "## Словарь, закон Ципфа и закон Хипса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQbetP7caOl"
      },
      "source": [
        "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhAcf6ZdcaOn"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sf0VUFMcaO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28debaf3-f787-42da-cc68-3a587cc61349"
      },
      "source": [
        "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
        "print(len(corpus))\n",
        "corpus[:10]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2870536\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcstqOJ3caPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4cb0f5-d415-4935-f9f9-2309f95cdcd3"
      },
      "source": [
        "freq_dict = Counter(corpus)\n",
        "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
        "list(freq_dict_sorted)[:10]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('не', 69472),\n",
              " ('и', 55166),\n",
              " ('в', 52902),\n",
              " ('я', 52818),\n",
              " ('RT', 38070),\n",
              " ('на', 35759),\n",
              " ('http', 32998),\n",
              " ('что', 31541),\n",
              " ('с', 27217),\n",
              " ('а', 26860)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aOt_E0_caPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "4b2625cc-ecff-4ad1-caf8-8867d9c5b22a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
        "plt.plot(first_100_freqs)\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VES6FwDycaP1"
      },
      "source": [
        "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTYFEchDcaP4"
      },
      "source": [
        "## О важности эксплоративного анализа\n",
        "\n",
        "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет, если вообще не убирать пунктуацию?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh-V2A2LcaP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28532aab-9c41-43f2-d55e-dfc544d7c3ed"
      },
      "source": [
        "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00     28050\n",
            "    positive       1.00      1.00      1.00     28659\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVsg62EmcaQP"
      },
      "source": [
        "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите признаки с самыми большими коэффициентами:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "791KkwrpcaQU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS2w2r4OcaQl"
      },
      "source": [
        "Посмотрим, как один из супер-значимых токенов справится с классификацией без всякого машинного обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXm6kC8BcaQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e46c78-1667-46b5-9900-7a9e3970ff51"
      },
      "source": [
        "cool_token = ')'\n",
        "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.85      0.92     32935\n",
            "    positive       0.83      1.00      0.91     23774\n",
            "\n",
            "    accuracy                           0.91     56709\n",
            "   macro avg       0.92      0.93      0.91     56709\n",
            "weighted avg       0.93      0.91      0.92     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKhGelRYcaQ8"
      },
      "source": [
        "## Символьные n-граммы\n",
        "\n",
        "Теперь в качестве признаков используем, например, униграммы символов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDVOQo_ycaRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "626af702-baa1-4e1b-d3ed-693be8b12cb2"
      },
      "source": [
        "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.99      1.00      1.00     27688\n",
            "    positive       1.00      0.99      1.00     29021\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhgl797-caRS"
      },
      "source": [
        "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или иначе, на символах классифицировать тоже можно: для некоторых задач (например, для определения языка) признаки - символьные n-граммы работают очень неплохо.\n",
        "\n",
        "Ещё одна замечательная особенность признаков-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готовых анализаторов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC34Hv70caRV"
      },
      "source": [
        "## Регулярки\n",
        "\n",
        "(если осталось время)\n",
        "\n",
        "Вообще, часто бывает так, что для конкретного случая нужен особый способ токенизации, и надо самостоятельно написать регулярку. Или, например, перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
        "\n",
        "Навык полезный, давайте в нём тоже потренируемся."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuIpMEb6caRZ"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HAkI_oFcaRu"
      },
      "source": [
        "### findall\n",
        "возвращает список всех найденных совпадений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnSmc38bcaRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a864c821-873e-40dd-aa10-e46d72e1c21d"
      },
      "source": [
        "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abcd', 'abca']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI5I4rukcaSB"
      },
      "source": [
        "Вопрос на внимательность: почему нет abcx?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dgI0YGocaSk"
      },
      "source": [
        "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04a6ugT-caSm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeyVPV_HcaS0"
      },
      "source": [
        "### split\n",
        "разделяет строку по заданному шаблону\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvUViO08caS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c9ba6a-d7e2-4b2c-d96e-37c5315460b9"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie', ' weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCtZSYRacaTF"
      },
      "source": [
        "можно указать максимальное количество разбиений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G797L28YcaTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6e2152-e66d-4843-cc54-915c101468bb"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit = 2)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie, weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fydg4ioHcaTU"
      },
      "source": [
        "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSJT2coicaTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e7230d-ee02-4670-e4f5-e92aa5d8e0d0"
      },
      "source": [
        "result = re.split(',', 'apple,pear,banana')\n",
        "print ([a[0] + a[1] for a in result])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ap', 'pe', 'ba']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPPk70tjcaTi"
      },
      "source": [
        "### sub\n",
        "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
        "\n",
        "параметры: (pattern, repl, string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euUczQ9pcaTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e60b8e-7f1f-457d-fd25-4200be54401d"
      },
      "source": [
        "result = re.sub('a', 'b', 'abcabc')\n",
        "print (result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bbcbbc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ-9QA5tcaTw"
      },
      "source": [
        "**Задание**: напишите регулярку, которая заменяет все цифры в строке на \"DIG\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1sQlaDWcaTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3865ef-d6ab-4e83-b74e-ab6228e5cf85"
      },
      "source": [
        "result = re.sub('\\d', 'DIG', 'abc5ab2c')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abcDIGabDIGc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qld28QPkcaT-"
      },
      "source": [
        "**Задание**: напишите регулярку, которая убирает url из строки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CogHtkUCcaUA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej-my8jacaUK"
      },
      "source": [
        "### compile\n",
        "компилирует регулярное выражение в отдельный объект"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUNF3LC8caUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e582d5-4f67-45d6-f2f7-77e3ae6485b4"
      },
      "source": [
        "# Пример: построение списка всех слов строки:\n",
        "prog = re.compile('[А-Яа-яё\\-]+')\n",
        "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv_oyL62caUb"
      },
      "source": [
        "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5qlsN-EcaUe"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hPLs3XkcaUv"
      },
      "source": [
        "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
        "\n",
        "```\n",
        "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCMRHxajcaUz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgzNJpFtcaV4"
      },
      "source": [
        "Если всё ещё осталось время: [регулярочный кроссворд ¯\\_(ツ)_/¯](https://mariolurig.com/crossword/)"
      ]
    }
  ]
}